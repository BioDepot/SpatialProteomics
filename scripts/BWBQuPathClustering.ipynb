{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0877b085-558d-4a99-a372-c0b6981afac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use \"numpy<2\" until version compatibility is fixed\n",
    "%pip install \"numpy<2\"\n",
    "%pip install pandas\n",
    "%pip install scanpy\n",
    "%pip install igraph\n",
    "%pip install leidenalg\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e82d49-203b-451a-91a1-097572fb0183",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir_path = os.getenv('clustering_outdir')\n",
    "if outputdir_path is None:\n",
    "    outputdir_path = '/data/clustering_data_export/'\n",
    "\n",
    "if not os.path.exists(outputdir_path):\n",
    "    os.makedirs(outputdir_path)\n",
    "\n",
    "# Make an output directory for generated graphs/plots,\n",
    "# next to clustering output directory\n",
    "plot_output_dir = os.path.join(Path(outputdir_path).parents[0], \"cluster_plots\")\n",
    "if not os.path.exists(plot_output_dir):\n",
    "    os.makedirs(plot_output_dir)\n",
    "\n",
    "\n",
    "print(outputdir_path)\n",
    "print(plot_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a3c837-df2f-4a46-b809-e36b515ea2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with segmentation data stored in 'segmentation_dir' env variable\n",
    "segmentation_dir_path = os.getenv('segmentation_dir')\n",
    "if segmentation_dir_path is None:\n",
    "    segmentation_dir_path = '/data/segmentation_data/'\n",
    "\n",
    "# Read all CSV files in the segmentation directory, store them in pandas DataFrames\n",
    "segmentation_data = []\n",
    "for filename in os.listdir(segmentation_dir_path):\n",
    "    print(filename)\n",
    "    if filename.endswith('cell-measurements.csv'):\n",
    "        file_path = os.path.join(segmentation_dir_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        segmentation_data.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "df = pd.concat(segmentation_data, ignore_index = True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d59d35-ef15-45d8-920c-84d905699ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regions/annotations in segmentation data files\n",
    "print(df['Parent'].unique())\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c11d3cd-07d3-4331-91d6-53301afa9da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If certain regions/annotations are processed, uncomment the line below and add to list\n",
    "# df = df[df['Parent'] == 'Test Core']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f8e4e-ec35-40b5-bdfe-c5b3ad5e47e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def normalize_data(data):\n",
    "    cofactors = data.quantile(0.20)\n",
    "    cofactors[cofactors <= 0] = 1e-6\n",
    "    data_arcsinh = np.arcsinh(data / cofactors)\n",
    "    data_zscored_biomarkers = data_arcsinh.apply(zscore, axis=0)\n",
    "    data_zscored_cells = data_zscored_biomarkers.apply(zscore, axis=1)\n",
    "    return data_zscored_cells\n",
    "\n",
    "def normalize_cell_data(data):\n",
    "    \"\"\"\n",
    "    Normalize cell data using three steps:\n",
    "    1. Arcsinh transformation with cofactor equal to the 20th percentile of each biomarker.\n",
    "    2. Z-standard normalization across all cells for each biomarker.\n",
    "    3. Z-standard normalization across all biomarkers for each cell.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pandas DataFrame where rows represent cells and columns represent biomarkers.\n",
    "\n",
    "    Returns:\n",
    "    - normalized_data: pandas DataFrame with normalized values.\n",
    "    \"\"\"\n",
    "    # Step 1: Arcsinh transformation\n",
    "    def arcsinh_transform(column):\n",
    "        p20 = np.percentile(column, 20)\n",
    "        if p20 > 0:\n",
    "            return np.arcsinh(column / p20)\n",
    "        else:\n",
    "            return np.arcsinh(column)\n",
    "    \n",
    "    # Apply arcsinh transformation to each biomarker (column)\n",
    "    arcsinh_data = data.apply(arcsinh_transform, axis=0)\n",
    "    \n",
    "    # Step 2: Z-standard normalization across all cells for each biomarker\n",
    "    z_normalized_biomarker = arcsinh_data.apply(\n",
    "        lambda col: (col - col.mean()) / col.std(), axis=0\n",
    "    )\n",
    "    \n",
    "    # Step 3: Z-standard normalization across all biomarkers for each cell\n",
    "    z_normalized_cells = z_normalized_biomarker.apply(\n",
    "        lambda row: (row - row.mean()) / row.std(), axis=1\n",
    "    )\n",
    "    \n",
    "    # Return the final normalized dataframe\n",
    "    return z_normalized_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88d7c01-bebd-4fb1-8f29-2bfada21445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the annotations/regions for each cell in a list\n",
    "# TODO: If there is a mismatch in the number of cells and regions, you may need to filter df['ROI'] to \"Polygon\" first\n",
    "regions = df['Parent'].to_list()\n",
    "print(len(regions))\n",
    "# regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40067280-4a95-4482-abdd-c66821693cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of exclude\n",
    "excludeColumns = [\"min\", \"max\", \"median\", \"std.dev\", \"area\", \"length\", \"circularity\", \"solidity\", \"diameter\", \"cluster\"]\n",
    "df_to_export = df[['Centroid X µm', 'Centroid Y µm', 'Image']]\n",
    "data_cleaned = df.iloc[:, 11:]\n",
    "na_rows_to_drop = data_cleaned[data_cleaned.isna().any(axis=1)].index\n",
    "\n",
    "data_cleaned = data_cleaned.drop(index=na_rows_to_drop)\n",
    "df_to_export = df_to_export.drop(index=na_rows_to_drop)\n",
    "\n",
    "# Filter out columns that contain any of the  to exclude\n",
    "data_cleaned = data_cleaned.loc[:, ~data_cleaned.columns.str.contains('|'.join(excludeColumns), case=False)]\n",
    "print(data_cleaned.shape)\n",
    "print(df_to_export.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7895a1e0-9912-4356-9164-092ea760fc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of biomarkers to exclude\n",
    "excludeBiomarkers = ['DAPI', 'CD123', 'Ki67', 'CD3e', 'CD8', 'Pan-Cytokeratin', 'CD107a', 'CD4', 'CD20', 'PCNA', 'CD141', 'aSMA', 'TCF7', 'CD138',\n",
    "                     'Vimentin', 'Ecadherin', 'PD1', 'MHC I', 'PDL1', 'TOX', 'CD11b', 'GATA-3', 'HLA-DR', 'CD14', 'FoxP3', 'CD34', 'CD15',\n",
    "                     'CD45RO', 'CXCR3', 'S100A8/9', 'Tim-3', 'GzmB', 'CD31', 'p16', 'SOX2', 'EpCAM', 'VISTA', 'CD66b', 'CXCR1', 'CD45',\n",
    "                     'T-bet/TBX21', 'CD163', 'CD56', 'CD68', 'LAG-3', 'LEF-1', 'MPO', 'CD11c', 'IFNG', 'PDGFr', 'Galectin-3', 'Cathepsin-L',\n",
    "                     'Podoplanin', 'H2A.X', 'GP100', 'CD27', 'T62', 'BX090', 'T55']\n",
    "excludeBiomarkers = [\"DAPI\"]\n",
    "# Filter out columns that contain any of the columns to exclude\n",
    "if len(excludeBiomarkers) > 0:\n",
    "    data_cleaned = data_cleaned.loc[:, ~data_cleaned.columns.str.contains('|'.join(excludeBiomarkers), case=False)]\n",
    "print(data_cleaned.shape)\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc56da6-e00b-49b6-8b01-6535d8af5b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = normalize_cell_data(data_cleaned)\n",
    "print(data_cleaned.shape)\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9f9743-bfeb-4840-bfa8-8b49ffae629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of keywords for compartmental data\n",
    "compartments = ['cell', 'membrane', 'cytoplasm', 'nucleus']\n",
    "\n",
    "# Function to filter the data for each compartment\n",
    "def filter_by_compartment(data, compartment):\n",
    "    # Select columns that contain the specific keyword\n",
    "    return data[[col for col in data.columns if compartment in col.lower()]]\n",
    "\n",
    "# Separate data for each compartment\n",
    "cell_data = filter_by_compartment(data_cleaned, 'cell')\n",
    "membrane_data = filter_by_compartment(data_cleaned, 'membrane')\n",
    "cytoplasm_data = filter_by_compartment(data_cleaned, 'cytoplasm')\n",
    "nucleus_data = filter_by_compartment(data_cleaned, 'nucleus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9f9819-43aa-45cf-87f1-376c9c6503f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cell_data.shape)\n",
    "cell_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29dd831-0367-444b-8d87-024071499ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(membrane_data.shape)\n",
    "membrane_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b2be3-057c-40a5-b952-283f3ccfd538",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nucleus_data.shape)\n",
    "nucleus_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e8bb4e-03df-41f9-80d6-bacbbe43ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cytoplasm_data.shape)\n",
    "cytoplasm_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c6d855-149a-4eed-be82-218b59b17999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Leiden algorithm and plot UMAP for each compartment\n",
    "def leiden_clustering_and_umap(compartment_data, compartment_name):\n",
    "    # Create AnnData object from the compartment data\n",
    "    adata = sc.AnnData(compartment_data.values)\n",
    "    adata.var_names = compartment_data.columns\n",
    "    \n",
    "    # NEW: add regions to adata as new column\n",
    "    adata.obs['region'] = regions[:adata.shape[0]] # Ensure the length matches the number of cells\n",
    "    \n",
    "    \n",
    "    # Step 4: Normalize and preprocess the data (if required)\n",
    "    # Usually for cell data, normalization is required, but you can adjust as needed\n",
    "    # (Normalization is already done in the previous steps)\n",
    "    #sc.pp.log1p(adata)  # Log-transforming the data to reduce skewness\n",
    "\n",
    "    # Batch effect correction with ComBat, use 'region' as batch key\n",
    "    # Useful for multiple regions and/or image sources\n",
    "    sc.pp.combat(adata, key = 'region')\n",
    "    \n",
    "    # Step 5: Compute neighborhood graph\n",
    "    sc.pp.neighbors(adata, n_neighbors=30)\n",
    "    \n",
    "    # Step 6: Run Leiden clustering\n",
    "    sc.tl.leiden(adata, resolution=1.0)  # You can tweak the resolution parameter\n",
    "    \n",
    "    # Step 7: Visualize the clustering result using UMAP\n",
    "    sc.tl.umap(adata, min_dist=0.0001)\n",
    "    sc.pl.umap(adata, color='leiden', title=f'Leiden Clustering - {compartment_name}', show=False)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "\n",
    "    plt.savefig(os.path.join(plot_output_dir, \"umap.png\"), bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136332b2-487f-4a82-a494-99519f3ee1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "# Run Leiden clustering and UMAP for each compartment\n",
    "cell_adata = leiden_clustering_and_umap(cell_data, 'Cell')\n",
    "#membrane_adata = leiden_clustering_and_umap(membrane_data, 'Membrane')\n",
    "#cytoplasm_adata = leiden_clustering_and_umap(cytoplasm_data, 'Cytoplasm')\n",
    "#nucleus_adata = leiden_clustering_and_umap(nucleus_data, 'Nucleus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ecf947-b078-4d15-b7e8-77fa97975ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb669bc8-17bc-45a5-81a5-e2e26c493982",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_adata.obs['leiden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebaba30-cfc8-4417-9df1-7319703599c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expression_df = pd.DataFrame(cell_adata.X, index=cell_adata.obs_names, columns=cell_adata.var_names)\n",
    "clusters_data = expression_df.copy()\n",
    "clusters_data['leiden'] = cell_adata.obs['leiden']\n",
    "\n",
    "clusters_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed2cd6-45c8-4454-a767-206a525d8599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster_expresssion_mean = clusters_data.groupby('leiden').mean()\n",
    "cluster_expresssion_mean\n",
    "\n",
    "%pip install openpyxl\n",
    "cluster_expresssion_mean.to_excel(os.path.join(plot_output_dir, \"cluster_means.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b28d0-1153-4837-ab77-9c300cc73105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_heatmap(compartment_data, compartment_name):\n",
    "    #pio.renderers.default = 'iframe'\n",
    "    # Sample data\n",
    "    clusters = compartment_data.obs['leiden']\n",
    "    \n",
    "    # Extract expression data as a DataFrame\n",
    "    expression_data = pd.DataFrame(compartment_data.X, index=compartment_data.obs_names, columns=compartment_data.var_names)\n",
    "    \n",
    "    # Combine clusters with expression data\n",
    "    data_with_clusters = expression_data.copy()\n",
    "    data_with_clusters['leiden'] = clusters\n",
    "    \n",
    "    # Group by clusters and calculate the mean expression per cluster\n",
    "    mean_expression_per_cluster = data_with_clusters.groupby('leiden').mean()\n",
    "    heatmap_df = mean_expression_per_cluster.T\n",
    "    \n",
    "    clustergram = dashbio.Clustergram(\n",
    "        data=heatmap_df,\n",
    "        cluster='all',\n",
    "        column_labels=list(heatmap_df.columns.values),\n",
    "        row_labels=list(heatmap_df.index.str.replace(f': {compartment_name}: Mean', '', regex=False)),\n",
    "        color_map='Jet',\n",
    "        #color_continuous_scale='Jet',\n",
    "        #color_map=[[0.1, '#971D2B'], [0.2, '#C74637'], [.3, '#E58256'], [.4, '#F3C17E'], [.5, '#FBEEAE'],[.6, '#EFF7DF'], [.7, '#C3E0EB'], [.8, '#8CB5D3'], [.9, '#5779B2'], [1.0, '#323690']],  # Color scale\n",
    "        height=1200,  # Height of the clustergram\n",
    "        width=1000,  # Width of the clustergram,\n",
    "        #display_ratio=[0.4, 0.6]\n",
    "    )\n",
    "    \n",
    "    clustergram.for_each_trace(\n",
    "        lambda t: t.update(hovertemplate=\"Cluster: %{x}<br>Biomarker: %{y}<br>Value: %{z}\")\n",
    "        if isinstance(t, go.Heatmap)\n",
    "        else t\n",
    "    )\n",
    "\n",
    "    return clustergram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf5a58f-be0f-41eb-bca0-d0f5cf643b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install dash\n",
    "%pip install dash_bio\n",
    "%pip install dash-renderer\n",
    "%pip install dash_html_components\n",
    "%pip install dash_core_components\n",
    "%pip install kaleido\n",
    "import kaleido\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import dash_bio as dashbio\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "#py.init_notebook_mode()\n",
    "\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1625c6fb-d296-4707-85d0-233e12d34c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "clustergram = clustering_heatmap(cell_adata, 'Cell')\n",
    "fig = go.Figure(clustergram)\n",
    "heatmap_location = os.path.join(plot_output_dir, \"heatmap.html\")\n",
    "fig.write_html(heatmap_location)\n",
    "display(clustergram)  # Explicitly display it#clustergram_nucleus = clustering_heatmap(nucleus_adata, 'Nucleus')\n",
    "#display(clustergram_nucleus)\n",
    "#clustergram_cytoplasm = clustering_heatmap(cytoplasm_adata, 'Cytoplasm')\n",
    "#display(clustergram_cytoplasm)\n",
    "#clustergram_membrane = clustering_heatmap(membrane_adata, 'Membrane')\n",
    "#display(clustergram_membrane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8dd2da-f835-443c-afd6-d792d8618ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_to_export.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da262207-86aa-4dbc-933a-d3f58fda7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_export['Leiden Cluster Label'] =  cell_adata.obs['leiden'].values\n",
    "#print(cell_adata.uns['leiden_colors'])\n",
    "cluster_colors = cell_adata.uns['leiden_colors']\n",
    "df_to_export['cluster_color'] = df_to_export['Leiden Cluster Label'].map(lambda x: cluster_colors[int(x)])\n",
    "print(df_to_export.head())\n",
    "df_to_export.to_csv(\"\".join([outputdir_path, '/leiden_clustering_export.csv']), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835dc90e-e2ad-49a4-9651-824b44dc874b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
